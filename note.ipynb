{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772c156b",
   "metadata": {},
   "source": [
    "Importing necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82efe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2c020",
   "metadata": {},
   "source": [
    "Reading csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed6ed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 441456 entries, 0 to 441455\n",
      "Columns: 330 entries, _STATE to _AIDTST3\n",
      "dtypes: float64(323), object(7)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('2015.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d126702",
   "metadata": {},
   "source": [
    "Selecting columns from data that are relevant plus target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_add=[\"BPHIGH4\", \"TOLDHI2\", \"CVDINFR4\", \"CVDCRHD4\", \"CVDSTRK3\", \"ASTHMA3\", \"ASTHNOW\", \"CHCSCNCR\", \"CHCOCNCR\", \"CHCCOPD1\", \"HAVARTH3\", \"ADDEPEV2\",\n",
    "                \"CHCKIDNY\", \"SEX\", \"USENOW3\", \"FTJUDA1_\", \"FRUTDA1_\", \"BEANDAY_\", \"GRENDAY_\", \"_STATE\",\"ORNGDAY_\", \"VEGEDA1_\", \"EXERANY2\",\n",
    "                \"EXRACT11\", \"EXERHMM1\", \"STRENGTH\", \"ADEAT1\", \"_AGEG5YR\", \"_BMI5\", \"_SMOKER3\", \"DROCDY3_\", \"_TOTINDA\", \"PA1MIN_\", \"DIABETE3\"]\n",
    "\n",
    "data=data.filter(columns_to_add, axis=1)\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1be80",
   "metadata": {},
   "source": [
    "Cleaning data and fixing format issues(null values, irrelevant values) and selecting certain US states from the data for easier processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50de035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list1=[\"TOLDHI2\", \"CVDINFR4\", \"CVDCRHD4\", \"CVDSTRK3\", \"ASTHMA3\", \"ASTHNOW\", \"CHCSCNCR\", \"CHCOCNCR\", \"CHCCOPD1\", \"HAVARTH3\", \"ADDEPEV2\",\n",
    "                \"CHCKIDNY\"]\n",
    "list2=[ \"EXERANY2\",\"EXRACT11\", \"EXERHMM1\", \"STRENGTH\", \"ADEAT1\", \"_TOTINDA\", \"BPHIGH4\",\"TOLDHI2\", \"CVDINFR4\", \"CVDCRHD4\",\n",
    "        \"CVDSTRK3\", \"ASTHMA3\", \"ASTHNOW\", \"CHCSCNCR\", \"CHCOCNCR\", \"CHCCOPD1\", \"HAVARTH3\", \"ADDEPEV2\",\n",
    "        \"CHCKIDNY\", \"SEX\" ]\n",
    "list3=[\"FTJUDA1_\", \"FRUTDA1_\", \"BEANDAY_\", \"GRENDAY_\", \"ORNGDAY_\", \"VEGEDA1_\", \"PA1MIN_\", \"_BMI5\"]\n",
    "\n",
    "rows_to_drop=[]\n",
    "\n",
    "\n",
    "data[[\"BPHIGH4\", \"DIABETE3\"]]=data[[\"BPHIGH4\", \"DIABETE3\"]].replace([2,4], 3)\n",
    "data[\"DIABETE3\"]=data[\"DIABETE3\"].replace(3,0)\n",
    "data[list1]=data[list1].replace([7,9,np.nan], 2)\n",
    "data[\"USENOW3\"]=data[\"USENOW3\"].replace([7,9,np.nan], 3)\n",
    "data[list3]=data[list3].fillna(data[list3].mean())\n",
    "data[\"_SMOKER3\"]=data[\"_SMOKER3\"].replace(9,4)\n",
    "data[\"DROCDY3_\"]=data[\"DROCDY3_\"].replace(900,0)\n",
    "\n",
    "mask = data[[\"BPHIGH4\", \"DIABETE3\"]].isna() | data[[\"BPHIGH4\", \"DIABETE3\"]].isin([7,9])\n",
    "mask2= data[\"_STATE\"].isin( [2, 6, 8, 12, 42, 55, 22])\n",
    "\n",
    "rows_to_drop=data.index[mask.any(axis=1)].tolist()\n",
    "rows_to_drop+=data.index[data[\"_AGEG5YR\"].isin([14])].tolist()\n",
    "rows_to_drop+=data.index[~mask2].tolist()\n",
    "\n",
    "rows_to_drop=list(set(rows_to_drop))\n",
    "data.drop(labels=rows_to_drop, axis=0, inplace=True)\n",
    "data.drop(labels=\"_STATE\", axis=1)\n",
    "\n",
    "\n",
    "clean_data=pd.get_dummies(data, columns=list2)\n",
    "\n",
    "clean_data.info(verbose=True, show_counts=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4487c7",
   "metadata": {},
   "source": [
    "Splitting the data in training and testing sets and conversion to torch tensors. Also administered the data to DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=clean_data[\"DIABETE3\"]\n",
    "X=clean_data.drop(labels=\"DIABETE3\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, train_size=.8, test_size=.2, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test=X_train.astype(float), X_test.astype(float), y_train.astype(float), y_test.astype(float)\n",
    "\n",
    "X_train_tensor=torch.tensor(X_train.to_numpy(), dtype=torch.float)\n",
    "X_test_tensor=torch.tensor(X_test.to_numpy(), dtype=torch.float)\n",
    "\n",
    "y_train_tensor=torch.tensor(y_train.to_numpy(), dtype=torch.float).view(-1, 1)\n",
    "y_test_tensor=torch.tensor(y_test.to_numpy(), dtype=torch.float).view(-1, 1)\n",
    "\n",
    "train_dataset=TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset=TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=40, shuffle=True)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a4653",
   "metadata": {},
   "source": [
    "Defining the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d64f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NNCalc(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NNCalc, self).__init__()\n",
    "        self.fc1=nn.Linear(306, 128)\n",
    "        self.fc2=nn.Linear(128, 64)\n",
    "        self.fc3=nn.Linear(64, 32)\n",
    "        self.fcf=nn.Linear(32, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "        #self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fcf(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "model_NN=NNCalc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e86e67",
   "metadata": {},
   "source": [
    "Initializing loss and optimizer. The loss is being initialized with a biased weight for the positive labels, to reflect the imbalance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07796be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss=nn.BCEWithLogitsLoss(pos_weight=torch.tensor([7.78]))\n",
    "optimizer=torch.optim.Adam(model_NN.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfd652",
   "metadata": {},
   "source": [
    "Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8fb5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epoch_num=1000\n",
    "\n",
    "model_NN.train()\n",
    "\n",
    "\n",
    "for nr in range(epoch_num):\n",
    "    total_loss=0\n",
    "    for values, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output=model_NN(values)\n",
    "        BCELoss=loss(output,labels)\n",
    "        BCELoss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=BCELoss.item()\n",
    "    if((nr+1)%100==0):\n",
    "        print(\"The loss is\",total_loss/len(train_dataloader))\n",
    "           \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de258a3",
   "metadata": {},
   "source": [
    "Evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN.eval()\n",
    "total_loss=0\n",
    "predictions=[]\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dataloader:\n",
    "        out=model_NN(values)\n",
    "        loss_test=loss(out,labels)\n",
    "        preds=(torch.sigmoid(out)>.5).int()\n",
    "        total_loss+=loss_test.item()\n",
    "        predictions.extend(preds)\n",
    "    print(\"Test loss is \", total_loss/len(test_dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08df43",
   "metadata": {},
   "source": [
    "Final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "155eb9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.7117801283789893\n",
      "Report is\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.70      0.81      9802\n",
      "         1.0       0.25      0.78      0.38      1259\n",
      "\n",
      "    accuracy                           0.71     11061\n",
      "   macro avg       0.61      0.74      0.60     11061\n",
      "weighted avg       0.88      0.71      0.76     11061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "acc=accuracy_score(y_test, predictions)\n",
    "report=classification_report(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy is \", acc)\n",
    "print(\"Report is\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab939d82",
   "metadata": {},
   "source": [
    "The results are the following:\n",
    "\n",
    "Accuracy is  0.7117801283789893\n",
    "Report is\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.70      0.81      9802\n",
    "         1.0       0.25      0.78      0.38      1259\n",
    "\n",
    "    accuracy                           0.71     11061\n",
    "   macro avg       0.61      0.74      0.60     11061\n",
    "weighted avg       0.88      0.71      0.76     11061\n",
    "\n",
    "The results could be interpreted as far from ideal, but in my personal consideration the recall for the positive values, which is imperative for this model, is reasonably high(78%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
